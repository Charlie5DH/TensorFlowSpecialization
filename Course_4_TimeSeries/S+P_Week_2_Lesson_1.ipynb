{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zX4Kg8DUTKWO"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BOjujz601HcS",
    "outputId": "22ce5d72-e30f-4550-ec81-7ba0267f4240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNxEwApNp8R9"
   },
   "source": [
    "First, we'll create a simple dataset, and it's just a simple range containing 10 elements from zero to nine. We'll print each one out on its own line as you can see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "asEdslR_05O_",
    "outputId": "b90d2c3e-1daf-4cce-f44e-5da87c594e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "for val in dataset:\n",
    "   print(val.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4oo88FVfqH2j"
   },
   "source": [
    "Next, we'll window the data into chunks of five items, shifting by one each time. We'll see that this gives us the output of the first five items, and then the second five items, and then the third five items, etc. At the end of the dataset, when there isn't enough data to give us five items, you'll see shorter lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Lrv_ghSt1lgQ",
    "outputId": "da9f0c2e-ff92-4e6f-f7f4-c03b19b9e5c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 \n",
      "1 2 3 4 5 \n",
      "2 3 4 5 6 \n",
      "3 4 5 6 7 \n",
      "4 5 6 7 8 \n",
      "5 6 7 8 9 \n",
      "6 7 8 9 \n",
      "7 8 9 \n",
      "8 9 \n",
      "9 \n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1)\n",
    "for window_dataset in dataset:\n",
    "  for val in window_dataset:\n",
    "    print(val.numpy(), end=\" \")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8Js-2MqqKUD"
   },
   "source": [
    "To just get chunks of five records, we'll set `drop_reminder` to true. When we run it, we'll see that our data looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "QLEq6MG-2DN2",
    "outputId": "5d2d0a3f-7315-4fea-ad8c-5bcbddaf4415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 \n",
      "1 2 3 4 5 \n",
      "2 3 4 5 6 \n",
      "3 4 5 6 7 \n",
      "4 5 6 7 8 \n",
      "5 6 7 8 9 \n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "for window_dataset in dataset:\n",
    "  for val in window_dataset:\n",
    "    print(val.numpy(), end=\" \")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaLi5jVFq1Kq"
   },
   "source": [
    "We've got even sets that are the same size. TensorFlow likes its data to be in numpy format. So we can convert it easily by calling the dot numpy method and when we print it, we can see it's now listed in square brackets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "PJ9CAHlJ2ODe",
    "outputId": "7cb14f53-cfc3-42c3-b61b-3ade439a2731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[1 2 3 4 5]\n",
      "[2 3 4 5 6]\n",
      "[3 4 5 6 7]\n",
      "[4 5 6 7 8]\n",
      "[5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "for window in dataset:\n",
    "  print(window.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Be42GGBjrq49"
   },
   "source": [
    "Next up is to split into x's and y's or features and labels. We'll take the last column as the label, and we'll split using a lambda. We'll split the data into column minus one, which is all of the columns except the last one, and minus one column which is the last one only. Now we can see that we have a set of four items and a single item. Remember that the minus one column denotes the last value in the list, and column minus one denotes everything about the last value. As such, we can see zero, one, two, three and one, two, three, four before the split just for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "DryEZ2Mz2nNV",
    "outputId": "29be6b52-7055-4fb7-d03f-d844bde560bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3] [4]\n",
      "[1 2 3 4] [5]\n",
      "[2 3 4 5] [6]\n",
      "[3 4 5 6] [7]\n",
      "[4 5 6 7] [8]\n",
      "[5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
    "for x,y in dataset:\n",
    "  print(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FepMYyklsRj0"
   },
   "source": [
    "Next of course, is to shuffle the data. This is achieved with the shuffle method. This helps us to rearrange the data so as not to accidentally introduce a sequence bias. Multiple runs will show the data in different arrangements because it gets shuffled randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "1tl-0BOKkEtk",
    "outputId": "ac00de68-4c32-4ce1-97fa-b3712654aa26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6] [7]\n",
      "[2 3 4 5] [6]\n",
      "[4 5 6 7] [8]\n",
      "[0 1 2 3] [4]\n",
      "[1 2 3 4] [5]\n",
      "[5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
    "dataset = dataset.shuffle(buffer_size=10)\n",
    "for x,y in dataset:\n",
    "  print(x.numpy(), y.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VwGD7RTRs6mL"
   },
   "source": [
    " Finally, comes batching. By setting a batch size of two, our data gets batched into two x's and two y's at a time. For example, as we saw earlier, if x is zero, one, two, three, we can see that the corresponding y is four or if x is five, six, seven, eight, then our y is nine. So that's the workbook with the code that splits a data series into windows. Try it out for yourself, and once you're familiar with what it does, proceed to the next video. There you'll move to the seasonal dataset that you've been using two dates, and with this windowing technique, you'll see how to set up x's and y's that can be fed into a neural network to see how it performs with predicting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "Wa0PNwxMGapy",
    "outputId": "d6b458e2-d540-4dff-c113-a8e511a0abbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[1 2 3 4]\n",
      " [2 3 4 5]]\n",
      "y =  [[5]\n",
      " [6]]\n",
      "x =  [[3 4 5 6]\n",
      " [5 6 7 8]]\n",
      "y =  [[7]\n",
      " [9]]\n",
      "x =  [[4 5 6 7]\n",
      " [0 1 2 3]]\n",
      "y =  [[8]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
    "dataset = dataset.shuffle(buffer_size=10)\n",
    "dataset = dataset.batch(2).prefetch(1)\n",
    "for x,y in dataset:\n",
    "  print(\"x = \", x.numpy())\n",
    "  print(\"y = \", y.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAErWaKAtmf1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "S+P Week 2 Lesson 1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
